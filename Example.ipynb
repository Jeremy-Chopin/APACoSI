{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit"
  },
  "interpreter": {
   "hash": "029e8b7a0429205878dfe54335b43c024148146ac0db2ac5338879305f804ae8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "from scipy import ndimage\n",
    "from skimage.measure import label, regionprops\n",
    "from scipy.ndimage.filters import median_filter\n",
    "from scipy.ndimage.measurements import label\n",
    "import pickle"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import Graphs\n",
    "from src import QAP\n",
    "from src import utils\n",
    "from src import metrics\n",
    "from src import refinement as ref\n",
    "import pipeline_QAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_largest_cc_results(image_cnn, nb_classes):\n",
    "\n",
    "    image = np.zeros(image_cnn.shape)\n",
    "\n",
    "    for i in range(1, nb_classes+1):\n",
    "        mask = np.where(image_cnn == i, 1, 0).astype(np.bool)\n",
    "        lbl = label(mask, connectivity=2)\n",
    "        regions = regionprops(lbl)\n",
    "        biggest_region = None\n",
    "        for region in regions:\n",
    "            if biggest_region is None:\n",
    "                biggest_region = region\n",
    "            else:\n",
    "                if biggest_region.area < region.area:\n",
    "                    biggest_region = region\n",
    "        image = np.where(lbl == biggest_region.label, i, image)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_img_to_nii(img, path):\n",
    "\n",
    "    nib_image = nib.Nifti1Image(img, np.eye(4))\n",
    "\n",
    "    nib_image.header.get_xyzt_units()\n",
    "    nib_image.to_filename(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_from_dict(image_lbl_path, dict_path, nb_classes):\n",
    "    loaded_image = nib.load(image_lbl_path).get_fdata()\n",
    "    with open(dict_path, 'rb') as handle:\n",
    "        b = pickle.load(handle)\n",
    "\n",
    "    dims = list(loaded_image.shape)\n",
    "\n",
    "    dims.append(nb_classes+1)\n",
    "\n",
    "    base_image = np.zeros(dims)\n",
    "\n",
    "    uni = np.unique(loaded_image)\n",
    "\n",
    "    for value in uni:\n",
    "\n",
    "        region_mask = np.where(loaded_image == value, 1, 0)\n",
    "\n",
    "        if len(loaded_image.shape) > 2:\n",
    "            proba_mask = np.expand_dims(region_mask, axis=3) * b[value]\n",
    "        else:\n",
    "            proba_mask = np.expand_dims(region_mask, axis=2) * b[value]\n",
    "\n",
    "        base_image = base_image + proba_mask\n",
    "    return base_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage = 50\n",
    "\n",
    "iteration = 1\n",
    "\n",
    "KNOWLEDGES_PATH = os.path.join(\".\", \"sub_datasets_brain\", str(percentage), str(iteration),  \"knowledges\", \"Brain_Dist_relative.npy\")\n",
    "\n",
    "DICT_DIRECTORY = os.path.join(\".\", \"sub_datasets_brain\", str(percentage), str(iteration), \"dict\")\n",
    "\n",
    "RESULTS_DIRECTORY = os.path.join(\".\", \"sub_datasets_brain\", str(percentage), str(iteration), \"results\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.5\n",
    "\n",
    "nb_classes = 14\n",
    "\n",
    "specifier = \"centroid\"\n",
    "\n",
    "max_node_matching = 2\n",
    "max_node_refinement = np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isdir(RESULTS_DIRECTORY) == False:\n",
    "    os.mkdir(RESULTS_DIRECTORY)\n",
    "\n",
    "RESULTS_DIRECTORY_specifier = os.path.join(\".\", \"sub_datasets_brain\", str(percentage), str(iteration), \"results\", specifier)\n",
    "\n",
    "if os.path.isdir(RESULTS_DIRECTORY_specifier) == False:\n",
    "    os.mkdir(RESULTS_DIRECTORY_specifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_files = int(len(os.listdir(DICT_DIRECTORY)) / 2)\n",
    "\n",
    "times = []\n",
    "errors = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ok1\n"
     ]
    }
   ],
   "source": [
    "for k in range(0, nb_files):\n",
    "\n",
    "    t_initial = time.time()\n",
    "\n",
    "    try:\n",
    "        patient_path = os.path.join(RESULTS_DIRECTORY_specifier, \"P\" + str(k))\n",
    "        if os.path.isdir(patient_path) == False:\n",
    "            os.mkdir(patient_path)\n",
    "\n",
    "        \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "            Chargement des donnÃ©es\n",
    "        \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "\n",
    "        image_lbl_path = os.path.join(DICT_DIRECTORY, str(k) + \"_lbl.nii.gz\")\n",
    "        dict_path = os.path.join(DICT_DIRECTORY, str(k) + \"_dict.pickle\")\n",
    "        print(\"ok1\")\n",
    "        pr_mask = load_image_from_dict(image_lbl_path, dict_path, nb_classes)\n",
    "\n",
    "        print(\"ok\")\n",
    "\n",
    "        #pr_mask = np.load(os.path.join(SEGMENTATION_DIRECTORY, str(k) + \"pr.npy\"))\n",
    "        #gt_mask = np.load(os.path.join(SEGMENTATION_DIRECTORY, str(k) + \"gt.npy\"))\n",
    "        image_cnn = np.argmax(pr_mask, axis=len(pr_mask.shape) - 1)\n",
    "        #intensity_input = np.load(os.path.join(SEGMENTATION_DIRECTORY, str(k) + \"intensity.npy\"))\n",
    "\n",
    "        dims = len(image_cnn.shape)\n",
    "\n",
    "        \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "            Etapes de pre-traitements\n",
    "        \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "\n",
    "        #pr_mask = np.transpose(pr_mask, (1,2,3,0))\n",
    "        \n",
    "        #image_cnn = np.where(intensity_input > 0, image_cnn, 0)\n",
    "\n",
    "        #image_cnn = ndimage.median_filter(image_cnn, 3)\n",
    "\n",
    "        pr_mask = pr_mask[:,:,:, 1:nb_classes + 1]\n",
    "\n",
    "        Am= Graphs.load_structural_model(KNOWLEDGES_PATH, nb_classes)\n",
    "\n",
    "        Am = np.transpose(Am, (2,0,1))\n",
    "\n",
    "        #Am = np.transpose(Am, (1,0,2))\n",
    "\n",
    "        labelled_image, regions, matching_inter, merging_final = pipeline_QAP.pipeline_QAP(specifier, alpha, pr_mask, image_cnn, nb_classes, Am, max_node_matching, max_node_refinement)\n",
    "        \n",
    "        merging_final_filtre, distance_recap = ref.correct_merging_distance(labelled_image, regions, matching_inter, merging_final, 20)\n",
    "\n",
    "        # Etape 4 : Obtention des images\n",
    "\n",
    "        biggest_CC_image = get_largest_cc_results(image_cnn, nb_classes)\n",
    "\n",
    "        matching_image = ref.create_images_from_ids(labelled_image, matching_inter, regions)\n",
    "\n",
    "        proposal_image = ref.create_images_from_ids(labelled_image, merging_final, regions)\n",
    "\n",
    "        post_refinement_image_CC = get_largest_cc_results(proposal_image, nb_classes)\n",
    "\n",
    "        image_refinement_distance = ref.create_images_from_ids(labelled_image, merging_final_filtre, regions)\n",
    "\n",
    "        #image_refinement_distance = median_filter(image_refinement_distance, 3)\n",
    "\n",
    "        # Etape 4 : Sauvegardes des images\n",
    "\n",
    "        cnn_output_path = os.path.join(patient_path, str(k) + \"_cnn_output.nii.gz\")\n",
    "        save_img_to_nii(image_cnn, cnn_output_path)\n",
    "\n",
    "        gt_path = os.path.join(patient_path, str(k) + \"_gt.nii.gz\")\n",
    "        save_img_to_nii(gt_mask, gt_path)\n",
    "\n",
    "        cnn_CC = os.path.join(patient_path, str(k) + \"_cnn_output_CC.nii.gz\")\n",
    "        save_img_to_nii(biggest_CC_image, cnn_CC)\n",
    "        \n",
    "        proposal_path = os.path.join(patient_path, str(k) + \"_proposal.nii.gz\")\n",
    "        save_img_to_nii(proposal_image, proposal_path)\n",
    "\n",
    "        post_processing_path = os.path.join(patient_path, str(k) + \"_proposal_CC.nii.gz\")\n",
    "        save_img_to_nii(post_refinement_image_CC, post_processing_path)\n",
    "\n",
    "        \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "                    Metrics\n",
    "        \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "\n",
    "        datas = [\"dice\", \"precision\", \"recall\", \"hausdorff\", \"nb_CC\"]\n",
    "\n",
    "        score_cnn = metrics.all_informations_data_frame(datas, image_cnn, gt_mask)\n",
    "\n",
    "        score_cnn_CC = metrics.all_informations_data_frame(datas, biggest_CC_image, gt_mask)\n",
    "\n",
    "        score_before_refinement = metrics.all_informations_data_frame(datas, matching_image, gt_mask)\n",
    "\n",
    "        score_after_refinement = metrics.all_informations_data_frame(datas, proposal_image, gt_mask)\n",
    "\n",
    "        score_post_refinement_CC = metrics.all_informations_data_frame(datas, post_refinement_image_CC, gt_mask)\n",
    "\n",
    "        result = pd.concat([score_cnn, score_cnn_CC, score_before_refinement, score_after_refinement, score_post_refinement_CC], axis=1, join=\"inner\")\n",
    "\n",
    "        print(result)\n",
    "\n",
    "        result_path = os.path.join(patient_path, \"result.csv\")\n",
    "        result.to_csv(result_path)\n",
    "\n",
    "        processing_time = time.time() - t_initial\n",
    "        times.append(processing_time)\n",
    "\n",
    "    except:\n",
    "        print(\"error on file\" + str(k))\n",
    "        errors.append(patient_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(RESULTS_DIRECTORY_specifier, \"error_log.txt\"), \"w\") as output:\n",
    "    output.write(str(errors))\n",
    "\n",
    "times = np.asarray(times)\n",
    "np.savetxt(os.path.join(RESULTS_DIRECTORY_specifier, \"processing_time.csv\"), times)"
   ]
  }
 ]
}